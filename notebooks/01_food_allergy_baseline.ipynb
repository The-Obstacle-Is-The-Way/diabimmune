{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-0",
   "source": [
    "# 01: Food Allergy Baseline (Track A)\n",
    "\n",
    "Baseline notebook for the DIABIMMUNE Track A dataset (HF microbiome embeddings + corrected `Month_*.csv` metadata).\n",
    "\n",
    "Design goals (see `docs/specs/03_NOTEBOOK_STRUCTURE.md`):\n",
    "- Self-contained (no project helper modules).\n",
    "- Assertion-driven (fail fast if invariants break).\n",
    "- Leakage-safe evaluation (subject-level aggregation + `StratifiedGroupKFold`).\n",
    "- Cumulative horizon analyses: `≤3mo`, `≤6mo`, `≤12mo`, and `all`.\n",
    "- LOCO analysis to probe country confounding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-1",
   "source": [
    "## 0) Setup & Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-2",
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "from IPython.display import display\n",
    "\n",
    "# Configuration\n",
    "RANDOM_SEED = 42\n",
    "N_SPLITS_OUTER = 5\n",
    "HORIZONS = [None, 3, 6, 12]  # None = all samples (association baseline)\n",
    "\n",
    "# Paths\n",
    "# Note: nbconvert executes notebooks with cwd set to the notebook's directory,\n",
    "# so we auto-detect the repo root by searching for `data/processed/`.\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data\" / \"processed\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find repo root from {start.resolve()} (expected data/processed/)\"\n",
    "    )\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "METADATA_DIR = REPO_ROOT / \"data\" / \"processed\" / \"longitudinal_wgs_subset\"\n",
    "EMBEDDINGS_PATH = REPO_ROOT / \"data\" / \"processed\" / \"hf_legacy\" / \"microbiome_embeddings_100d.h5\"\n",
    "# Results go to `notebooks/results/` (alongside the notebook) for transplantability.\n",
    "# Note: nbconvert executes notebooks with cwd set to the notebook's directory.\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Print versions\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-3",
   "source": [
    "## 1) Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-4",
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "assert METADATA_DIR.exists(), f\"Missing METADATA_DIR: {METADATA_DIR.resolve()}\"\n",
    "assert EMBEDDINGS_PATH.exists(), f\"Missing EMBEDDINGS_PATH: {EMBEDDINGS_PATH.resolve()}\"\n",
    "\n",
    "# Load all Month CSVs\n",
    "dfs = []\n",
    "for csv_path in sorted(METADATA_DIR.glob(\"Month_*.csv\")):\n",
    "    month = int(csv_path.stem.split(\"_\")[1])\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"month\"] = month\n",
    "    dfs.append(df)\n",
    "metadata = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Load embeddings\n",
    "embeddings_dict = {}\n",
    "with h5py.File(EMBEDDINGS_PATH, \"r\") as f:\n",
    "    for key in f.keys():\n",
    "        embeddings_dict[key] = f[key][:]\n",
    "\n",
    "# Merge\n",
    "metadata[\"embedding\"] = metadata[\"sid\"].map(embeddings_dict)\n",
    "df = metadata.dropna(subset=[\"embedding\"])  # Should be 0 drops if aligned\n",
    "\n",
    "# Extract arrays\n",
    "X = np.stack(df[\"embedding\"].values)\n",
    "y = df[\"label\"].values\n",
    "patient_ids = df[\"patient_id\"].values\n",
    "countries = df[\"country\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-5",
   "source": [
    "## 2) Integrity Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-6",
   "outputs": [],
   "source": [
    "# Counts\n",
    "print(f\"Samples: {len(df)}\")\n",
    "print(f\"Unique patients: {df['patient_id'].nunique()}\")\n",
    "print(f\"Label distribution: {df['label'].value_counts().to_dict()}\")\n",
    "print(f\"Country distribution: {df['country'].value_counts().to_dict()}\")\n",
    "\n",
    "# Assertions\n",
    "assert X.shape == (785, 100), f\"Expected (785, 100), got {X.shape}\"\n",
    "assert len(y) == 785\n",
    "assert df[\"patient_id\"].nunique() == 212\n",
    "assert len(df) == len(metadata), f\"Expected 0 dropped rows, dropped {len(metadata) - len(df)}\"\n",
    "\n",
    "# Check: each sample in exactly one month\n",
    "assert df[\"sid\"].duplicated().sum() == 0, \"Duplicate SRS IDs found!\"\n",
    "\n",
    "# Check: labels consistent per patient\n",
    "labels_per_patient = df.groupby(\"patient_id\")[\"label\"].nunique()\n",
    "assert (labels_per_patient == 1).all(), \"Inconsistent labels within patient!\"\n",
    "\n",
    "# Horizon sanity checks (Track A; month derived from file name)\n",
    "def horizon_counts(m: int):\n",
    "    d = df[df[\"month\"] <= m]\n",
    "    return len(d), d[\"patient_id\"].nunique(), d[\"label\"].value_counts().to_dict(), d[\"country\"].value_counts().to_dict()\n",
    "\n",
    "print(\"Horizon counts:\")\n",
    "for m in [3, 6, 12]:\n",
    "    n_samp, n_pat, labels, countries_m = horizon_counts(m)\n",
    "    print(f\"  month<={m}: samples={n_samp}, patients={n_pat}, labels={labels}, countries={countries_m}\")\n",
    "\n",
    "assert horizon_counts(3)[0] == 45\n",
    "assert horizon_counts(6)[0] == 110\n",
    "assert horizon_counts(12)[0] == 307\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-7",
   "source": [
    "## 3) ANALYSES 1–4: Association Baseline + Cumulative Horizons (Subject-Level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-8",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "\n",
    "outer_cv = StratifiedGroupKFold(n_splits=N_SPLITS_OUTER, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "def build_subject_table(samples_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    subj = samples_df.groupby(\"patient_id\").agg(\n",
    "        label=(\"label\", \"first\"),\n",
    "        country=(\"country\", \"first\"),\n",
    "        n_samples=(\"sid\", \"count\"),\n",
    "    )\n",
    "    subj[\"embedding\"] = samples_df.groupby(\"patient_id\")[\"embedding\"].apply(\n",
    "        lambda x: np.mean(np.stack(x.to_list()), axis=0)\n",
    "    )\n",
    "    return subj.reset_index()\n",
    "\n",
    "def run_cv(subj_df: pd.DataFrame, horizon_label: str) -> list[dict]:\n",
    "    X_subj = np.stack(subj_df[\"embedding\"].to_list())\n",
    "    y_subj = subj_df[\"label\"].to_numpy()\n",
    "    groups = subj_df[\"patient_id\"].to_numpy()\n",
    "\n",
    "    fold_rows = []\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X_subj, y_subj, groups=groups)):\n",
    "        X_train, X_test = X_subj[train_idx], X_subj[test_idx]\n",
    "        y_train, y_test = y_subj[train_idx], y_subj[test_idx]\n",
    "\n",
    "        model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                C=1.0,\n",
    "                class_weight=\"balanced\",\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=2000,\n",
    "                random_state=RANDOM_SEED,\n",
    "            )),\n",
    "        ])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"horizon\": horizon_label,\n",
    "            \"fold\": fold_idx,\n",
    "            \"n_train_subjects\": len(y_train),\n",
    "            \"n_test_subjects\": len(y_test),\n",
    "            \"auroc\": roc_auc_score(y_test, y_pred_proba),\n",
    "            \"auprc\": average_precision_score(y_test, y_pred_proba),\n",
    "            \"f1\": f1_score(y_test, y_pred),\n",
    "        })\n",
    "    return fold_rows\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "for m in HORIZONS:\n",
    "    if m is None:\n",
    "        horizon_label = \"all\"\n",
    "        df_h = df.copy()\n",
    "    else:\n",
    "        horizon_label = f\"≤{m}mo\"\n",
    "        df_h = df[df[\"month\"] <= m].copy()\n",
    "\n",
    "    subj = build_subject_table(df_h)\n",
    "    cv_results.extend(run_cv(subj, horizon_label=horizon_label))\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(cv_df)\n",
    "\n",
    "# Summary by horizon (mean ± std across folds)\n",
    "summary_rows = []\n",
    "for horizon_label, g in cv_df.groupby(\"horizon\"):\n",
    "    summary_rows.append({\n",
    "        \"horizon\": horizon_label,\n",
    "        \"auroc_mean\": g[\"auroc\"].mean(),\n",
    "        \"auroc_std\": g[\"auroc\"].std(),\n",
    "        \"auprc_mean\": g[\"auprc\"].mean(),\n",
    "        \"auprc_std\": g[\"auprc\"].std(),\n",
    "        \"f1_mean\": g[\"f1\"].mean(),\n",
    "        \"f1_std\": g[\"f1\"].std(),\n",
    "    })\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY (mean ± std across folds)\")\n",
    "print(\"=\"*60)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-9",
   "source": [
    "## 4) LOCO: Leave-One-Country-Out (Per Horizon, Where Meaningful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-10",
   "outputs": [],
   "source": [
    "loco_results = []\n",
    "\n",
    "for m in HORIZONS:\n",
    "    if m is None:\n",
    "        horizon_label = \"all\"\n",
    "        df_h = df.copy()\n",
    "    else:\n",
    "        horizon_label = f\"≤{m}mo\"\n",
    "        df_h = df[df[\"month\"] <= m].copy()\n",
    "\n",
    "    subj = build_subject_table(df_h)\n",
    "    X_subj = np.stack(subj[\"embedding\"].to_list())\n",
    "    y_subj = subj[\"label\"].to_numpy()\n",
    "    countries_subj = subj[\"country\"].to_numpy()\n",
    "\n",
    "    for held_out in [\"FIN\", \"EST\", \"RUS\"]:\n",
    "        # At <=3 months, RUS has too few subjects (and no positives) for meaningful LOCO.\n",
    "        if m == 3 and held_out == \"RUS\":\n",
    "            continue\n",
    "\n",
    "        train_mask = countries_subj != held_out\n",
    "        test_mask = countries_subj == held_out\n",
    "\n",
    "        y_test = y_subj[test_mask]\n",
    "        # AUROC is undefined if held-out set has only one class\n",
    "        if len(set(y_test)) < 2:\n",
    "            continue\n",
    "\n",
    "        X_train, y_train = X_subj[train_mask], y_subj[train_mask]\n",
    "        X_test = X_subj[test_mask]\n",
    "\n",
    "        model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                C=1.0,\n",
    "                class_weight=\"balanced\",\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=2000,\n",
    "                random_state=RANDOM_SEED,\n",
    "            )),\n",
    "        ])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        loco_results.append({\n",
    "            \"horizon\": horizon_label,\n",
    "            \"held_out\": held_out,\n",
    "            \"n_train_subjects\": len(y_train),\n",
    "            \"n_test_subjects\": len(y_test),\n",
    "            \"auroc\": roc_auc_score(y_test, y_pred_proba),\n",
    "            \"auprc\": average_precision_score(y_test, y_pred_proba),\n",
    "        })\n",
    "\n",
    "loco_df = pd.DataFrame(loco_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOCO RESULTS (Leave-One-Country-Out)\")\n",
    "print(\"=\"*60)\n",
    "display(loco_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-11",
   "source": [
    "## 5) Results Summary & Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-12",
   "outputs": [],
   "source": [
    "# Save results\n",
    "cv_df.to_csv(RESULTS_DIR / \"cv_metrics.csv\", index=False)\n",
    "loco_df.to_csv(RESULTS_DIR / \"loco_metrics.csv\", index=False)\n",
    "summary_df.to_csv(RESULTS_DIR / \"cv_summary.csv\", index=False)\n",
    "\n",
    "print(\"Results saved to results/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-13a",
   "source": [
    "## Known Limitations\n",
    "\n",
    "**Onset timing is unknown.** The label is an *endpoint outcome* (eventual food allergy status), not a diagnosis at the time of sample collection. Any horizon may include post-onset samples for some infants.\n",
    "\n",
    "**Milk allergy can manifest very early.** Infants exposed to cow's milk protein via formula or breast milk can develop milk allergy in the first weeks of life. This weakens \"pure prediction\" claims even at ≤3 months.\n",
    "\n",
    "**Claim strength is a gradient, not a boundary:**\n",
    "- **≤3 months**: Strongest predictive framing (but still limited)\n",
    "- **≤6 months**: Moderate predictive framing\n",
    "- **≤12 months**: Mixed predictive/associative\n",
    "- **All samples**: Association only (includes post-onset samples)\n",
    "\n",
    "**Country confounding.** Allergy prevalence differs by country (FIN 49%, EST 38%, RUS 15%). LOCO analysis helps assess whether the model learns transferable microbiome signal vs country-specific batch effects.\n",
    "\n",
    "**Russia at ≤3 months.** Only 3 RUS patients at this horizon; LOCO results for RUS are not meaningful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-13b",
   "source": [
    "## Interpretation Guide\n",
    "\n",
    "**AUROC interpretation:**\n",
    "- 0.50 = random chance (no signal)\n",
    "- 0.55–0.65 = weak signal\n",
    "- 0.65–0.75 = moderate signal\n",
    "- 0.75+ = strong signal\n",
    "\n",
    "**LOCO interpretation:**\n",
    "- If LOCO AUROC ≈ CV AUROC: Model learns transferable microbiome patterns\n",
    "- If LOCO AUROC << CV AUROC: Model may be exploiting country-specific effects\n",
    "- If LOCO AUROC < 0.50: Model fails to generalize to held-out country\n",
    "\n",
    "**What to look for:**\n",
    "1. Does AUROC decrease as horizon decreases? (Expected: less data = noisier estimates)\n",
    "2. Is ≤3mo AUROC still above chance? (Key question for \"early prediction\" claim)\n",
    "3. Do LOCO results hold up? (Country confounding check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-13",
   "source": "## Reproducibility Footer"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-14",
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"REPRODUCIBILITY INFO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "print(f\"Outer CV splits: {N_SPLITS_OUTER}\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"Run completed: {datetime.now().isoformat()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}