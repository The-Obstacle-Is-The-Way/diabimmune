# Specs Index

These specs define a minimal, reproducible workflow for the **DIABIMMUNE food allergy classifier**.

---

## Two Modeling Tracks

**Track A: HF Embeddings Baseline (Current Focus)**
- Pre-computed 100-dim embeddings (785 samples / 212 patients)
- Ludo's corrected metadata with food-allergy-only labels
- Ready for modeling now

**Track B: 16S OTU Full Dataset (Future)**
- Raw 16S OTU table (1,450 labeled samples / 203 subjects)
- Requires embedding generation (ProkBERT pipeline)

---

## Implementation Order

0. `00_HYPOTHESIS.md` — hypotheses + horizons (prediction vs association)
1. `01_PROJECT_SETUP.md` — uv + strict tooling
2. `02_DATA_PIPELINE.md` — prepare 16S + (optional) HF legacy artifacts
3. `03_NOTEBOOK_STRUCTURE.md` — notebook layout (baseline LogReg + horizons)
4. `04_EVALUATION.md` — leakage-safe evaluation (StratifiedGroupKFold, horizons, LOCO)
5. `05_QUALITY.md` — lint/format/typecheck + notebook hygiene
6. `06_DATA_SCHEMA.md` — file formats + invariants
7. `07_OUTCOME_DEFINITION.md` — label + missingness policy
8. `08_FEATURE_ENGINEERING.md` — OTU transforms (no leakage)
9. `09_TESTING.md` — tests that enforce invariants
10. `10_EMBEDDINGS_PIPELINE.md` — ProkBERT + sample embeddings (planned)
11. `11_PROVENANCE.md` — source registry + provenance manifests

---

## Expected Artifacts

### Track A (HF Embeddings Baseline)

**Metadata** (`data/processed/longitudinal_wgs_subset/`):
- `Month_1.csv` through `Month_38.csv` (35 files)
- Columns: `sid, patient_id, country, label, allergen_class`

**Embeddings** (`data/processed/hf_legacy/`):
- `microbiome_embeddings_100d.h5` — 785 samples, 100-dim vectors
- `unified_samples.csv` — legacy metadata (for reference)

### Track B (16S OTU Full Dataset)

Generated by `scripts/prepare_16s_dataset.py`:
- `data/processed/16s/samples_food_allergy.csv`
- `data/processed/16s/otus_greengenes_ids.csv`
- `data/processed/16s/otu_counts.npz`
- `data/processed/16s/dataset_manifest.json`
